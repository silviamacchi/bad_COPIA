# -*- coding: utf-8 -*-
"""
/***************************************************************************
 BAD
                                 A QGIS plugin
 BAD_Burned Area Detector
 Generated by Plugin Builder: http://g-sherman.github.io/Qgis-Plugin-Builder/
                              -------------------
        begin                : 2023-01-24
        git sha              : $Format:%H$
        copyright            : (C) 2023 by Thomas Martinoli
        email                : th.martinoli96@gmail.com
 ***************************************************************************/

/***************************************************************************
 *                                                                         *
 *   This program is free software; you can redistribute it and/or modify  *
 *   it under the terms of the GNU General Public License as published by  *
 *   the Free Software Foundation; either version 2 of the License, or     *
 *   (at your option) any later version.                                   *
 *                                                                         *
 ***************************************************************************/
"""


from osgeo import gdal
import numpy as np

#new libraries
import requests
import pandas as pd
import zipfile
import os
import glob
import shutil

# Initialize Qt resources from file resources.py
from .resources import *

class SentinelSearch:
    def __init__(self,aoi,Start_date,End_date,Cloud,Limit_num):
        
        catalogue_odata_url = "https://catalogue.dataspace.copernicus.eu/odata/v1"
        collection_name = "SENTINEL-2"
        product_type = "S2MSI2A"
        search_period_start = f"{Start_date}T00:00:00.000Z"
        search_period_end = f"{End_date}T00:00:00.000Z"

        search_query = f"{catalogue_odata_url}/Products?$filter=Collection/Name eq '{collection_name}' and Attributes/OData.CSC.StringAttribute/any(att:att/Name eq 'productType' and att/OData.CSC.StringAttribute/Value eq '{product_type}') and Attributes/OData.CSC.DoubleAttribute/any(att:att/Name eq 'cloudCover' and att/OData.CSC.DoubleAttribute/Value le {Cloud}) and OData.CSC.Intersects(area=geography'SRID=4326;{aoi}') and ContentDate/Start gt {search_period_start} and ContentDate/Start lt {search_period_end}&$top={Limit_num}"

        print(f"""\n{search_query.replace(' ', "%20")}\n""")
        response = requests.get(search_query).json()
        self.result = pd.DataFrame.from_dict(response["value"])
        print(self.result['Name'])
        print(self.result.columns)

class download_and_save_zip:
    def __init__(self, url, headers, output_filename, output_tif):
        print(f"Attempting to download from: {url}")
        print(f"Saving to: {output_filename}")

        # Create a session and update headers
        session = requests.Session()
        session.headers.update(headers)

        try:
            # Perform the GET request
            response = session.get(url, stream=True)
            response.raise_for_status()

            # Legge il contenuto completo e lo mette in memoria (reads the complete content into memory)
            zip_data = response.content

            # Close the connection explicitly to avoid resource warnings
            response.close()

            with open(output_filename, 'wb') as f:
                f.write(zip_data)

            print(f"\nData saved to '{output_filename}' (Size: {len(zip_data)} bytes).")
            directory_path = os.path.dirname(output_tif)
            process_sentinel2_zip(output_filename, directory_path, output_tif)

        except requests.exceptions.RequestException as e:
            print(f"\nAn error occurred during the request: {e}")

def find_file_paths(safe_folder_path):
    # 1. Trova la cartella GRANULE
    granule_dir = os.path.join(safe_folder_path, 'GRANULE')
    if not os.path.isdir(granule_dir):
        raise FileNotFoundError(f"Impossibile trovare la cartella GRANULE a: {granule_dir}")

    # 2. Trova la cartella Granule ID (di solito una sola sottocartella)
    granule_id_folders = [d for d in os.listdir(granule_dir) if os.path.isdir(os.path.join(granule_dir, d))]
    
    if not granule_id_folders:
        raise FileNotFoundError(f"Impossibile trovare la cartella Granule ID all'interno di: {granule_dir}")
    
    # Prendi la prima (e di solito unica) cartella Granule ID
    granule_id_folder = granule_id_folders[0]
    full_granule_id_path = os.path.join(granule_dir, granule_id_folder)

    # 3. Trova la cartella IMG_DATA
    img_data_root = os.path.join(full_granule_id_path, "IMG_DATA")
    if not os.path.isdir(img_data_root):
        raise FileNotFoundError(f"Impossibile trovare la cartella IMG_DATA a: {img_data_root}")

    # 4. Dedurre il prefisso del file JP2
    r10m_path = os.path.join(img_data_root, "R10m")
    
    # Usa glob per trovare un file di banda (che contiene "_B0") in R10m
    # Questo esclude i file accessori come AOT, WVP, ecc.
    band_jp2_files = glob.glob(os.path.join(r10m_path, "*_B0*.jp2"))
    
    if not band_jp2_files:
        raise FileNotFoundError(f"Nessun file banda spettrale .jp2 trovato per dedurre il prefisso in {r10m_path}")
            
    # Prendiamo il primo file di banda (es. T34SGJ_..._B02_10m.jp2)
    first_file_name = os.path.basename(band_jp2_files[0])
    
    # Il prefisso è la parte prima della banda e della risoluzione (es. _B02_10m.jp2)
    # Troviamo l'indice dove inizia la specifica della banda (es. '_B02')
    
    parts = first_file_name.split('_')
    
    # Cerchiamo l'indice del primo elemento che inizia con 'B' (la banda)
    band_index = -1
    for i, part in enumerate(parts):
        if part.startswith('B'):
            band_index = i
            break
    
    if band_index != -1 and band_index > 0:
        # Il prefisso è tutto fino alla banda (escluso la banda)
        # Es: parts = ['T34SGJ', '20210717T092031', 'B02', '10m.jp2']
        # Risultato: 'T34SGJ_20210717T092031'
        file_prefix = "_".join(parts[:band_index]) 
    else:
        # Fallback se la struttura del nome è inaspettata
        raise ValueError(f"Impossibile dedurre il prefisso base dal file: {first_file_name}")
        
    return img_data_root, file_prefix

class process_sentinel2_zip:
    def __init__(self, zip_path, output_dir, final_output_path):
        
        # Salviamo output_dir come attributo per l'uso successivo (pulizia e percorso SAFE)
        self.output_dir = output_dir
        self.zip_path = zip_path # Salviamo zip_path per la pulizia finale

        # Inizializzazione della configurazione delle bande
        BAND_RESOLUTION_MAP = {
        "B01": "R60m", "B02": "R10m", "B03": "R10m", "B04": "R10m", 
        "B05": "R20m", "B06": "R20m", "B07": "R20m", "B08": "R10m", 
        "B8A": "R20m", "B09": "R60m", "B10": "R60m", "B11": "R20m", 
        "B12": "R20m", "SCL": "R20m"
        }
        BAND_LIST_ORDERED = list(BAND_RESOLUTION_MAP.keys())
        
        # Crea la directory di output se non esiste
        os.makedirs(self.output_dir, exist_ok=True)
        
        # Definisci il percorso completo della cartella SAFE
        safe_folder_name = None
        
        print(f"1. Estrazione del file: {self.zip_path}...")
        try:
            with zipfile.ZipFile(self.zip_path, 'r') as zip_ref:
                # Estrae il nome della cartella SAFE dalla prima voce
                safe_folder_name = zip_ref.namelist()[0].split('/')[0]
                
                # CHIAVE: Estrae tutto in output_dir (per risolvere Errno 30)
                zip_ref.extractall(self.output_dir)
                
                # Memorizza il percorso COMPLETO della cartella SAFE
                self.safe_folder_path = os.path.join(self.output_dir, safe_folder_name)

        except Exception as e:
            print(f"Errore durante l'estrazione del file ZIP: {e}")
            return
        
        # --- Ricerca Dinamica dei File ---
        try:
            # CHIAMATA AGGIORNATA: Passa il percorso COMPLETO alla funzione
            img_data_root, file_prefix = find_file_paths(self.safe_folder_path)
        except FileNotFoundError as e:
            print(f"Errore di struttura: {e}")
            self.clean_up(safe_folder_name, None, False) # Pulizia parziale in caso di errore
            return

        # Costruisce l'elenco completo dei percorsi dei file .jp2 ordinati
        input_files = []
        print(f"Identificatore immagine (prefisso): {file_prefix}")
        
        for band in BAND_LIST_ORDERED:
            resolution_folder = BAND_RESOLUTION_MAP[band]
            
            # Logica per il suffisso della risoluzione (standard Sentinel-2)
            if resolution_folder == "R10m":
                res_suffix = "_10m"
            elif resolution_folder == "R20m":
                res_suffix = "_20m"
            elif resolution_folder == "R60m":
                res_suffix = "_60m"
            else:
                res_suffix = "" 

            file_name = f"{file_prefix}_{band}{res_suffix}.jp2"
            file_path = os.path.join(img_data_root, resolution_folder, file_name)
            
            if os.path.exists(file_path):
                input_files.append(file_path)
            else:
                if band != "B10": 
                    print(f"Avviso: File della banda {band} non trovato a {file_path}. Skip.")
                    
        if not input_files:
            print("Errore: Nessun file banda valido trovato per l'elaborazione.")
            self.clean_up(safe_folder_name, None, False)
            return
            
        # Percorso temporaneo per il VRT (Virtual Raster)
        temp_vrt_path = os.path.join(self.output_dir, "temp_merged_native_res.vrt")

        # --- 2. Unione delle Bande con gdal.BuildVRT ---
        print(f"\n2. Creazione del VRT unito per {len(input_files)} bande in {temp_vrt_path}...")
        
        try:
            vrt_options = gdal.BuildVRTOptions(resampleAlg=gdal.GRIORA_NearestNeighbour, separate=True)
            gdal.BuildVRT(temp_vrt_path, input_files, options=vrt_options)
            print("Creazione VRT completata.")
        except Exception as e:
            print(f"Errore durante la creazione del VRT con gdal.BuildVRT: {e}")
            self.clean_up(safe_folder_name, temp_vrt_path, False)
            return
        # --- 3. Ricampionamento con gdal.Warp (Sostituisce gdalwarp) ---
        print(f"\n3. Ricampionamento/Creazione del GeoTIFF finale a 10m in {final_output_path}...")

        try:
            # gdal.Warp legge dal VRT e ricampiona/scrive l'output finale
            warp_options = gdal.WarpOptions(
                format='GTiff', 
                xRes=10.0, 
                yRes=10.0, # -tr 10 10 
                resampleAlg=gdal.GRA_CubicSpline # -r cubicspline
            )
            gdal.Warp(final_output_path, temp_vrt_path, options=warp_options)
            print("Ricampionamento a 10m completato con successo! ✅")
        except Exception as e:
            self.clean_up(safe_folder_name, temp_vrt_path, False)
            return
            
        # --- 4. Pulizia Finale ---
        self.clean_up(safe_folder_name, temp_vrt_path, True)

        print("\nProcesso completato.")
        print(f"Il tuo file GeoTIFF multistrato è disponibile qui: {final_output_path}")

    
    def clean_up(self, safe_folder_name, temp_vrt_path, remove_zip=True):
        """Funzione di pulizia ausiliaria."""
        
        # Rimuovi il VRT temporaneo
        if temp_vrt_path and os.path.exists(temp_vrt_path):
            try:
                os.remove(temp_vrt_path)
            except Exception as e:
                print(f"Avviso durante la pulizia del VRT: {e}")

        # Rimuovi la cartella SAFE estratta usando il percorso COMPLETO
        if hasattr(self, 'safe_folder_path') and os.path.exists(self.safe_folder_path):
             try:
                shutil.rmtree(self.safe_folder_path, ignore_errors=True)
                if safe_folder_name:
                    print(f"\nPulizia completata. Cartella '{safe_folder_name}' rimossa.")
             except Exception as e:
                print(f"Avviso durante la pulizia della cartella SAFE: {e}")

        # Rimuovi il file ZIP originale
        if remove_zip and os.path.exists(self.zip_path):
            try:
                os.remove(self.zip_path)
                print(f"File eliminato con successo: {self.zip_path}")
            except Exception as e:
                print(f"Avviso durante la pulizia del file ZIP: {e}")
class ReadingData:
    def __init__(self,First_path,Second_path):

        First_raster = gdal.Open(First_path, gdal.GA_ReadOnly) 
        Second_raster = gdal.Open(Second_path, gdal.GA_ReadOnly) 
        # Note GetRasterBand() takes band no. starting from 1 not 0

        First_matrix=First_raster.ReadAsArray()
        Second_matrix=Second_raster.ReadAsArray()

        self.FirstMatrix=First_matrix.astype(float)
        self.SecondMatrix=Second_matrix.astype(float)

        #self.Delta_matrix=S-F
      
        self.Bands=First_raster.RasterCount
        self.gt = First_raster.GetGeoTransform()
        self.proj= First_raster.GetProjection()

class MembershipFunction:
    def __init__(self,Matrix,K,x):
        
        self.MD=1/(1+np.exp(-K*(Matrix/10000-x)))
        
class OrderedWeigthAverage:
    def __init__(self,index,FinalBandMatix,w=None):
        
        Row=FinalBandMatix.shape[1]
        Column=FinalBandMatix.shape[2]
        self.Integrated_matrix=np.empty([Row,Column])

        #AND
        if index==1:
            self.filename="OWA_AND.tif"
            for i in range (Row):
                for j in range (Column):
                    vector=FinalBandMatix[:,i,j]
                    if (np.isnan(vector).any()):
                        value=np.nan
                    else:
                        value=min(vector)
                    self.Integrated_matrix[i,j]=value
            self.Integrated_matrix=np.nan_to_num(self.Integrated_matrix,nan=999)

        #almost AND
        if index==2:
            self.filename="OWA_almostAND.tif"
            for i in range (Row):
                for j in range (Column):
                    vector=FinalBandMatix[:,i,j]
                    if (np.isnan(vector).any()):
                        value=np.nan
                    else:
                        value=(np.sort(vector)[-1]+np.sort(vector)[-2])/2
                    self.Integrated_matrix[i,j]=value
            self.Integrated_matrix=np.nan_to_num(self.Integrated_matrix,nan=999)

        #AVERAGE
        if index==3:
            self.filename="OWA_AVERAGE.tif"
            for i in range (Row):
                for j in range (Column):
                    vector=FinalBandMatix[:,i,j]
                    if (np.isnan(vector).any()):
                        value=np.nan
                    else:
                        value=np.mean(vector)
                    self.Integrated_matrix[i,j]=value
            self.Integrated_matrix=np.nan_to_num(self.Integrated_matrix,nan=999)

        #almost OR:
        if index==4:
            self.filename="OWA_almostOR.tif"
            for i in range (Row):
                for j in range (Column):
                    vector=FinalBandMatix[:,i,j]
                    if (np.isnan(vector).any()):
                        value=np.nan
                    else:
                        value=(np.sort(vector)[0]+np.sort(vector)[1])/2
                    self.Integrated_matrix[i,j]=value
            self.Integrated_matrix=np.nan_to_num(self.Integrated_matrix,nan=999)

        #OR
        if index==5:      
            self.filename="OWA_OR.tif" 
            for i in range (Row):
                for j in range (Column):
                    vector=FinalBandMatix[:,i,j]
                    if (np.isnan(vector).any()):
                        value=np.nan
                    else:
                        value=max(vector)
                    self.Integrated_matrix[i,j]=value
            self.Integrated_matrix=np.nan_to_num(self.Integrated_matrix,nan=999)

        #UserChoice1
        if index==6:
            self.filename="OWA_UserChoice1.tif"
            for i in range (Row):
                for j in range (Column):
                    vector=FinalBandMatix[:,i,j] 
                    if (np.isnan(vector).any()):
                        value=np.nan
                    else:
                        value=np.dot(np.sort(vector),w)
                    self.Integrated_matrix[i,j]=value
            self.Integrated_matrix=np.nan_to_num(self.Integrated_matrix,nan=999)

        #UserChoice2
        if index==7:
            self.filename="OWA_UserChoice2.tif"
            for i in range (Row):
                for j in range (Column):
                    vector=FinalBandMatix[:,i,j] 
                    if (np.isnan(vector).any()):
                        value=np.nan
                    else:
                        value=np.dot(np.sort(vector),w)
                    self.Integrated_matrix[i,j]=value
            self.Integrated_matrix=np.nan_to_num(self.Integrated_matrix,nan=999)
class WriteLayer:
    def __init__(self,index,path,Matrix,NameBands,Nband,Xsize,Ysize,filename,gt,proj):
    
        if index==0:
            # se indice zero significa che l'utente non ha specificato nulla per 
            # cui devo trasformare il path per salvare il file in formato .tif
            array_path=path.split('/')
            array_path[-1]=filename
            splitter="/"
            self.output_path=splitter.join(array_path)
        else:
            self.output_path=path

        driver = gdal.GetDriverByName("GTiff")
        driver.Register()
        outds = driver.Create(self.output_path, xsize=Xsize,ysize=Ysize,bands=Nband, eType= gdal.GDT_Float32)
        outds.SetGeoTransform(gt)
        outds.SetProjection(proj)
        if Nband==1:
            outband = outds.GetRasterBand(Nband)
            outband.WriteArray(Matrix)
            outband.SetDescription(NameBands)
            outband.FlushCache()
            outband= None
        else:
            for i in range(Nband):
                outband = outds.GetRasterBand(i+1)
                outband.WriteArray(Matrix[i])
                outband.SetDescription(NameBands[i])
                outband.FlushCache()
                outband= None
        outds = None

class RegionGrowing:
    def __init__(self,Seed_threshold,Grow_threshold,Seed_matrix,Grow_matrix):

        Mask=np.where(Seed_matrix==999,999,0)     
        Seed_binary = np.where(Seed_matrix<Seed_threshold,0,1)+Mask
        Grow_binary = np.where(Grow_matrix<Grow_threshold,0,1)+Mask
        
        self.Raster=np.array([Seed_binary,Grow_binary])

        RasterPP=self.Raster.copy()

        sizeRow=RasterPP[0].shape[0]
        sizeColumn=RasterPP[0].shape[1]
        
        M=0
        N=np.count_nonzero(RasterPP[0])
        i=0
    
        while N!=M:
            M=N
            print('Iteration:',i,', Number of seeds:',N)
            i=i+1
            for j in range(sizeRow):
                for k in range(sizeColumn):
                                    
                    #insertion of the neighbors that are not considered yet
                    
                    if RasterPP[0,j,k]==1:
                                            
                        # neighbor examination                
                        
                        # above-left   
                        if j>0 and k>0 and RasterPP[0,j-1,k-1]==0 and RasterPP[1,j-1,k-1]==1:
                            RasterPP[0,j-1,k-1]=1
                            
                        
                        # above
                        if j>0 and RasterPP[0,j-1,k]==0 and RasterPP[1,j-1,k]==1:
                            RasterPP[0,j-1,k]=1
                            
                        
                        #above-right
                        if j>0 and k<=sizeColumn-2 and RasterPP[0,j-1,k+1]==0 and RasterPP[1,j-1,k+1]==1:
                            RasterPP[0,j-1,k+1]=1
                            
                            
                        #left
                        if k>0 and RasterPP[0,j,k-1]==0 and RasterPP[1,j,k-1]==1:
                            RasterPP[0,j,k-1]=1
                            
                        #right
                        if k<=sizeColumn-2 and RasterPP[0,j,k+1]==0 and RasterPP[1,j,k+1]==1:
                            RasterPP[0,j,k+1]=1
                            
                        
                        #below-left    
                        if j<=sizeRow-2 and k>0 and RasterPP[0,j+1,k-1]==0 and RasterPP[1,j+1,k-1]==1:
                            RasterPP[0,j+1,k-1]=1
                            
                        
                        #below    
                        if j<=sizeRow-2 and RasterPP[0,j+1,k]==0 and RasterPP[1,j+1,k]==1:
                            RasterPP[0,j+1,k]=1
                            
                        
                        #below-right    
                        if j<=sizeRow-2 and k<=sizeColumn-2 and RasterPP[0,j+1,k+1]==0 and RasterPP[1,j+1,k+1]==1:
                            RasterPP[0,j+1,k+1]=1
                                                                                          
            #condition that blocks the while
            N=np.count_nonzero(RasterPP[0])
            
        self.Result_matrix=RasterPP[0]

class Classification:
    def __init__(self,Matrix,LowerLevelList,UpperLevelList):

        Matrix=np.round(Matrix,3)
        M_ERH = np.where((Matrix>=LowerLevelList[0])&(Matrix<=UpperLevelList[0]),1,0)
        M_ERL = np.where((Matrix>=LowerLevelList[1])&(Matrix<=UpperLevelList[1]),2,0)
        M_U = np.where((Matrix>=LowerLevelList[2])&(Matrix<=UpperLevelList[2]),3,0)
        M_L = np.where((Matrix>=LowerLevelList[3])&(Matrix<=UpperLevelList[3]),4,0)
        M_ML = np.where((Matrix>=LowerLevelList[4])&(Matrix<=UpperLevelList[4]),5,0)
        M_MH = np.where((Matrix>=LowerLevelList[5])&(Matrix<=UpperLevelList[5]),6,0)
        M_H = np.where((Matrix>=LowerLevelList[6])&(Matrix<=UpperLevelList[6]),7,0)
        Matrix_class = M_ERH + M_ERL + M_U + M_L + M_ML + M_MH + M_H
        self.Final_Matrix = np.where(Matrix_class==0,99,Matrix_class)