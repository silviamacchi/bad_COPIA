# -*- coding: utf-8 -*-
"""
/***************************************************************************
 BAD
                                 A QGIS plugin
 BAD_Burned Area Detector
 Generated by Plugin Builder: http://g-sherman.github.io/Qgis-Plugin-Builder/
                              -------------------
        begin                : 2023-01-24
        git sha              : $Format:%H$
        copyright            : (C) 2023 by Thomas Martinoli
        email                : th.martinoli96@gmail.com
 ***************************************************************************/

/***************************************************************************
 *                                                                         *
 *   This program is free software; you can redistribute it and/or modify  *
 *   it under the terms of the GNU General Public License as published by  *
 *   the Free Software Foundation; either version 2 of the License, or     *
 *   (at your option) any later version.                                   *
 *                                                                         *
 ***************************************************************************/
"""


from osgeo import gdal
import numpy as np

#new libraries
import requests
import pandas as pd
from pyproj import CRS, Transformer
import json

# Initialize Qt resources from file resources.py
from .resources import *

class SentinelSearch:
    def __init__(self,aoi,Start_date,End_date,Cloud,Limit_num):
        
        catalogue_odata_url = "https://catalogue.dataspace.copernicus.eu/odata/v1"
        collection_name = "SENTINEL-2"
        product_type = "S2MSI2A"
        search_period_start = f"{Start_date}T00:00:00.000Z"
        search_period_end = f"{End_date}T00:00:00.000Z"

        search_query = f"{catalogue_odata_url}/Products?$filter=Collection/Name eq '{collection_name}' and Attributes/OData.CSC.StringAttribute/any(att:att/Name eq 'productType' and att/OData.CSC.StringAttribute/Value eq '{product_type}') and Attributes/OData.CSC.DoubleAttribute/any(att:att/Name eq 'cloudCover' and att/OData.CSC.DoubleAttribute/Value le {Cloud}) and OData.CSC.Intersects(area=geography'SRID=4326;{aoi}') and ContentDate/Start gt {search_period_start} and ContentDate/Start lt {search_period_end}&$top={Limit_num}&$orderby=ContentDate/Start asc"

        print(f"""\n{search_query.replace(' ', "%20")}\n""")
        response = requests.get(search_query).json()
        self.result = pd.DataFrame.from_dict(response["value"])
        if not self.result.empty:
            print(self.result['Name'])
            print(self.result.columns)
        else:
            self.result = pd.DataFrame({'Name': ["No available data for the given dates. Please select a different time period."]})
            print(self.result['Name'])
            
def transform_bbox_to_utm(bbox):
        lon_center = (bbox[0] + bbox[2]) / 2
        lat_center = (bbox[1] + bbox[3]) / 2
        
        # Find UTM zone
        utm_zone = int((lon_center + 180) / 6) + 1
        epsg_code = 32600 + utm_zone if lat_center >= 0 else 32700 + utm_zone
        utm_crs_url = f"http://www.opengis.net/def/crs/EPSG/0/{epsg_code}"
        
        crs_wgs84 = CRS.from_epsg(4326)
        crs_utm = CRS.from_epsg(epsg_code)
        transformer = Transformer.from_crs(crs_wgs84, crs_utm, always_xy=True)
        
        utm_w, utm_s = transformer.transform(bbox[0], bbox[1])
        utm_e, utm_n = transformer.transform(bbox[2], bbox[3])
        utm_bbox_list = [utm_w, utm_s, utm_e, utm_n]
        
        return utm_crs_url, utm_bbox_list

def Downloadsh(BBOX,date,output_name,username,password):
    token_url = "https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token"
    token_data = {
        "grant_type": "client_credentials",
        "client_id": username,
        "client_secret": password
    }
    token_response = requests.post(token_url, data=token_data)
    access_token = token_response.json().get("access_token")
    PROCESS_API_URL = "https://sh.dataspace.copernicus.eu/api/v1/process"
    UTM_CRS_URL, UTM_BBOX = transform_bbox_to_utm(BBOX)
    EVALSCRIPT = """
    function setup() {
    return {
        input: [
        {
            bands: ["B01", "B02", "B03", "B04", "B05", "B06", "B07", "B08", "B8A", "B09", "B11", "B12", "SCL"],
            units: "DN" 
        }
        ],
        output: [
        {
            id: "default",
            bands: 13,
            sampleType: "UINT16"
        }
        ]
    }
    }

    function evaluatePixel(samples) {
    return [
        samples.B01, samples.B02, samples.B03, samples.B04, samples.B05, samples.B06,
        samples.B07, samples.B08, samples.B8A, samples.B09, samples.B11, samples.B12,
        samples.SCL
    ];
    }
    """
    request_payload = {
        "input": {
            "bounds": {
                "bbox": UTM_BBOX,
                "properties": {
                    "crs": UTM_CRS_URL
                }
            },
            "data": [
                {
                    "type": "sentinel-2-l2a",
                    "dataFilter": {
                        "timeRange": {
                            "from": f"{date}T00:00:00Z",
                            "to": f"{date}T23:59:59Z"
                        }
                    }
                }
            ]
        },
        "output": {
            "resx": 10,  
            "resy": 10,  
            "crs": UTM_CRS_URL,
            "responses": [
                {
                    "identifier": "default",
                    "format": {
                        "type": "image/tiff"
                    }
                }
            ]
        },
        "evalscript": EVALSCRIPT
    }
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {access_token}"
    }
    try:
        response = requests.post(
            PROCESS_API_URL,
            headers=headers,
            json=request_payload,
            stream=True 
        )
        response.raise_for_status()

        with open(output_name, 'wb') as f:
            for chunk in response.iter_content(chunk_size=8192):
                f.write(chunk)

    except requests.exceptions.HTTPError as e:
        print(f"Error HTTP: {e}")
        try:
            error_details = response.json()
            print(f"Error (Sentinel Hub): {json.dumps(error_details, indent=2)}")
        except Exception:
            print("No details about the error.")

    except requests.exceptions.RequestException as e:
        print(f"Connection error: {e}")
class ReadingData:
    def __init__(self,First_path,Second_path):

        First_raster = gdal.Open(First_path, gdal.GA_ReadOnly) 
        Second_raster = gdal.Open(Second_path, gdal.GA_ReadOnly) 
        # Note GetRasterBand() takes band no. starting from 1 not 0

        First_matrix=First_raster.ReadAsArray()
        Second_matrix=Second_raster.ReadAsArray()

        self.FirstMatrix=First_matrix.astype(float)
        self.SecondMatrix=Second_matrix.astype(float)

        #self.Delta_matrix=S-F
      
        self.Bands=First_raster.RasterCount
        self.gt = First_raster.GetGeoTransform()
        self.proj= First_raster.GetProjection()

class MembershipFunction:
    def __init__(self,Matrix,K,x):
        
        self.MD=1/(1+np.exp(-K*(Matrix/10000-x)))
        
class OrderedWeigthAverage:
    def __init__(self,index,FinalBandMatix,w=None):
        
        Row=FinalBandMatix.shape[1]
        Column=FinalBandMatix.shape[2]
        self.Integrated_matrix=np.empty([Row,Column])

        #AND
        if index==1:
            self.filename="OWA_AND.tif"
            for i in range (Row):
                for j in range (Column):
                    vector=FinalBandMatix[:,i,j]
                    if (np.isnan(vector).any()):
                        value=np.nan
                    else:
                        value=min(vector)
                    self.Integrated_matrix[i,j]=value
            self.Integrated_matrix=np.nan_to_num(self.Integrated_matrix,nan=999)

        #almost AND
        if index==2:
            self.filename="OWA_almostAND.tif"
            for i in range (Row):
                for j in range (Column):
                    vector=FinalBandMatix[:,i,j]
                    if (np.isnan(vector).any()):
                        value=np.nan
                    else:
                        value=(np.sort(vector)[-1]+np.sort(vector)[-2])/2
                    self.Integrated_matrix[i,j]=value
            self.Integrated_matrix=np.nan_to_num(self.Integrated_matrix,nan=999)

        #AVERAGE
        if index==3:
            self.filename="OWA_AVERAGE.tif"
            for i in range (Row):
                for j in range (Column):
                    vector=FinalBandMatix[:,i,j]
                    if (np.isnan(vector).any()):
                        value=np.nan
                    else:
                        value=np.mean(vector)
                    self.Integrated_matrix[i,j]=value
            self.Integrated_matrix=np.nan_to_num(self.Integrated_matrix,nan=999)

        #almost OR:
        if index==4:
            self.filename="OWA_almostOR.tif"
            for i in range (Row):
                for j in range (Column):
                    vector=FinalBandMatix[:,i,j]
                    if (np.isnan(vector).any()):
                        value=np.nan
                    else:
                        value=(np.sort(vector)[0]+np.sort(vector)[1])/2
                    self.Integrated_matrix[i,j]=value
            self.Integrated_matrix=np.nan_to_num(self.Integrated_matrix,nan=999)

        #OR
        if index==5:      
            self.filename="OWA_OR.tif" 
            for i in range (Row):
                for j in range (Column):
                    vector=FinalBandMatix[:,i,j]
                    if (np.isnan(vector).any()):
                        value=np.nan
                    else:
                        value=max(vector)
                    self.Integrated_matrix[i,j]=value
            self.Integrated_matrix=np.nan_to_num(self.Integrated_matrix,nan=999)

        #UserChoice1
        if index==6:
            self.filename="OWA_UserChoice1.tif"
            for i in range (Row):
                for j in range (Column):
                    vector=FinalBandMatix[:,i,j] 
                    if (np.isnan(vector).any()):
                        value=np.nan
                    else:
                        value=np.dot(np.sort(vector),w)
                    self.Integrated_matrix[i,j]=value
            self.Integrated_matrix=np.nan_to_num(self.Integrated_matrix,nan=999)

        #UserChoice2
        if index==7:
            self.filename="OWA_UserChoice2.tif"
            for i in range (Row):
                for j in range (Column):
                    vector=FinalBandMatix[:,i,j] 
                    if (np.isnan(vector).any()):
                        value=np.nan
                    else:
                        value=np.dot(np.sort(vector),w)
                    self.Integrated_matrix[i,j]=value
            self.Integrated_matrix=np.nan_to_num(self.Integrated_matrix,nan=999)
class WriteLayer:
    def __init__(self,index,path,Matrix,NameBands,Nband,Xsize,Ysize,filename,gt,proj):
    
        if index==0:
            # se indice zero significa che l'utente non ha specificato nulla per 
            # cui devo trasformare il path per salvare il file in formato .tif
            array_path=path.split('/')
            array_path[-1]=filename
            splitter="/"
            self.output_path=splitter.join(array_path)
        else:
            self.output_path=path

        driver = gdal.GetDriverByName("GTiff")
        driver.Register()
        outds = driver.Create(self.output_path, xsize=Xsize,ysize=Ysize,bands=Nband, eType= gdal.GDT_Float32)
        outds.SetGeoTransform(gt)
        outds.SetProjection(proj)
        if Nband==1:
            outband = outds.GetRasterBand(Nband)
            outband.WriteArray(Matrix)
            outband.SetDescription(NameBands)
            outband.FlushCache()
            outband= None
        else:
            for i in range(Nband):
                outband = outds.GetRasterBand(i+1)
                outband.WriteArray(Matrix[i])
                outband.SetDescription(NameBands[i])
                outband.FlushCache()
                outband= None
        outds = None

class RegionGrowing:
    def __init__(self,Seed_threshold,Grow_threshold,Seed_matrix,Grow_matrix):

        Mask=np.where(Seed_matrix==999,999,0)     
        Seed_binary = np.where(Seed_matrix<Seed_threshold,0,1)+Mask
        Grow_binary = np.where(Grow_matrix<Grow_threshold,0,1)+Mask
        
        self.Raster=np.array([Seed_binary,Grow_binary])

        RasterPP=self.Raster.copy()

        sizeRow=RasterPP[0].shape[0]
        sizeColumn=RasterPP[0].shape[1]
        
        M=0
        N=np.count_nonzero(RasterPP[0])
        i=0
    
        while N!=M:
            M=N
            print('Iteration:',i,', Number of seeds:',N)
            i=i+1
            for j in range(sizeRow):
                for k in range(sizeColumn):
                                    
                    #insertion of the neighbors that are not considered yet
                    
                    if RasterPP[0,j,k]==1:
                                            
                        # neighbor examination                
                        
                        # above-left   
                        if j>0 and k>0 and RasterPP[0,j-1,k-1]==0 and RasterPP[1,j-1,k-1]==1:
                            RasterPP[0,j-1,k-1]=1
                            
                        
                        # above
                        if j>0 and RasterPP[0,j-1,k]==0 and RasterPP[1,j-1,k]==1:
                            RasterPP[0,j-1,k]=1
                            
                        
                        #above-right
                        if j>0 and k<=sizeColumn-2 and RasterPP[0,j-1,k+1]==0 and RasterPP[1,j-1,k+1]==1:
                            RasterPP[0,j-1,k+1]=1
                            
                            
                        #left
                        if k>0 and RasterPP[0,j,k-1]==0 and RasterPP[1,j,k-1]==1:
                            RasterPP[0,j,k-1]=1
                            
                        #right
                        if k<=sizeColumn-2 and RasterPP[0,j,k+1]==0 and RasterPP[1,j,k+1]==1:
                            RasterPP[0,j,k+1]=1
                            
                        
                        #below-left    
                        if j<=sizeRow-2 and k>0 and RasterPP[0,j+1,k-1]==0 and RasterPP[1,j+1,k-1]==1:
                            RasterPP[0,j+1,k-1]=1
                            
                        
                        #below    
                        if j<=sizeRow-2 and RasterPP[0,j+1,k]==0 and RasterPP[1,j+1,k]==1:
                            RasterPP[0,j+1,k]=1
                            
                        
                        #below-right    
                        if j<=sizeRow-2 and k<=sizeColumn-2 and RasterPP[0,j+1,k+1]==0 and RasterPP[1,j+1,k+1]==1:
                            RasterPP[0,j+1,k+1]=1
                                                                                          
            #condition that blocks the while
            N=np.count_nonzero(RasterPP[0])
            
        self.Result_matrix=RasterPP[0]

class Classification:
    def __init__(self,Matrix,LowerLevelList,UpperLevelList):

        Matrix=np.round(Matrix,3)
        M_ERH = np.where((Matrix>=LowerLevelList[0])&(Matrix<=UpperLevelList[0]),1,0)
        M_ERL = np.where((Matrix>=LowerLevelList[1])&(Matrix<=UpperLevelList[1]),2,0)
        M_U = np.where((Matrix>=LowerLevelList[2])&(Matrix<=UpperLevelList[2]),3,0)
        M_L = np.where((Matrix>=LowerLevelList[3])&(Matrix<=UpperLevelList[3]),4,0)
        M_ML = np.where((Matrix>=LowerLevelList[4])&(Matrix<=UpperLevelList[4]),5,0)
        M_MH = np.where((Matrix>=LowerLevelList[5])&(Matrix<=UpperLevelList[5]),6,0)
        M_H = np.where((Matrix>=LowerLevelList[6])&(Matrix<=UpperLevelList[6]),7,0)
        Matrix_class = M_ERH + M_ERL + M_U + M_L + M_ML + M_MH + M_H
        self.Final_Matrix = np.where(Matrix_class==0,99,Matrix_class)